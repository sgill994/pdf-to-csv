{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert JSON Responses \n",
    "with open(\"extracted_sections.json\", \"r\") as f:\n",
    "    pages_data = json.load(f)  \n",
    "\n",
    "sections_data = []\n",
    "for page in pages_data:\n",
    "    try:\n",
    "        response_dict = json.loads(page[\"Response\"])\n",
    "        if \"sections\" in response_dict:\n",
    "            sections_data.extend(response_dict[\"sections\"])\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error parsing JSON for page {page['Page']}\")\n",
    "\n",
    "with open(\"merged_sections.json\", \"w\") as f:\n",
    "    json.dump({\"sections\": sections_data}, f, indent=4)\n",
    "\n",
    "# Convert JSON to DataFrame\n",
    "df = pd.DataFrame(sections_data)\n",
    "\n",
    "# Handle \"use_prev_section\" placeholders from GPT parsed text\n",
    "to_drop = [] \n",
    "for idx in range(len(df) - 1):\n",
    "    if df.at[idx, \"Section\"] != \"use_prev_section\":\n",
    "        # Check for placeholder \"Sections\" to append for sections spanning multiple pages\n",
    "        for next_idx in range(idx + 1, len(df) - 1): \n",
    "            if df.at[next_idx, \"Section\"] == \"use_prev_section\":\n",
    "                df.at[idx, \"Section Body Text\"] += \"\\n\" + df.at[next_idx, \"Section Body Text\"]\n",
    "                to_drop.append(next_idx) \n",
    "            else:\n",
    "                break\n",
    "\n",
    "# Drop all placeholder rows from final DataFrame\n",
    "df.drop(index=to_drop, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Parent Section: remove last occurrence of '.' and all digits after it\n",
    "def compute_parent_section(section):\n",
    "    if \".\" in section:\n",
    "        return \".\".join(section.split(\".\")[:-1])\n",
    "    return \"\" \n",
    "df[\"Parent Section\"] = df[\"Section\"].apply(compute_parent_section)\n",
    "\n",
    "# Assign Level: count number of decimals in Section\n",
    "df[\"Level\"] = df[\"Section\"].apply(lambda x: x.count(\".\"))\n",
    "\n",
    "# Define last page number of document \n",
    "last_page = int(df[\"Start Page\"].max())\n",
    "\n",
    "# # Ensure \"Start Page\" is always stored as an integer\n",
    "# df[\"Start Page\"] = pd.to_numeric(df[\"Start Page\"], errors=\"coerce\").fillna(last_page).astype(int)\n",
    "\n",
    "# Create subset DF for End Page computations\n",
    "df_sub = df[[\"Parent Section\", \"Section\", \"Start Page\", \"Level\", \"Starts On New Page\"]].copy()\n",
    "df_sub[\"Original Index\"] = df_sub.index  \n",
    "df_sub[\"Start Page\"] = pd.to_numeric(df_sub[\"Start Page\"], errors=\"coerce\").astype(\"Int64\") \n",
    "df_sub[\"End Page\"] = df_sub[\"Start Page\"]\n",
    "# Apply shift() and retain correct data types\n",
    "df_sub[\"Next Seq Start Page\"] = df_sub[\"Start Page\"].shift(-1).fillna(last_page + 1)\n",
    "df_sub[\"Next Seq Starts On New Page\"] = df_sub[\"Starts On New Page\"].shift(-1).fillna(False).astype(bool)\n",
    "# Sort DataFrame by Level, Parent Section, and Section Number\n",
    "df_sub = df_sub.sort_values(by=[\"Level\", \"Parent Section\", \"Section\"]).reset_index(drop=True)\n",
    "\n",
    "# Loop through the DataFrame to assign End Page\n",
    "for i in range(len(df_sub) - 2):\n",
    "    # Extracting variables for readability\n",
    "    curr_level = df_sub.iloc[i][\"Level\"]\n",
    "    next_level = df_sub.iloc[i + 1][\"Level\"]\n",
    "    curr_parent = df_sub.iloc[i][\"Parent Section\"]\n",
    "    next_parent = df_sub.iloc[i + 1][\"Parent Section\"]\n",
    "\n",
    "    next_start_page_sorted = df_sub.iloc[i + 1][\"Start Page\"]\n",
    "    next_start_page_org = df_sub.iloc[i][\"Next Seq Start Page\"]\n",
    "    next_snp_sorted = df_sub.iloc[i + 1][\"Starts On New Page\"]\n",
    "    next_snp_org = df_sub.iloc[i][\"Next Seq Starts On New Page\"]\n",
    "\n",
    "    # Case 1: Same Level & Same Parent\n",
    "    if curr_level == next_level and curr_parent == next_parent:\n",
    "        df_sub.at[i, \"End Page\"] = next_start_page_sorted - 1 if next_snp_sorted else next_start_page_sorted\n",
    "\n",
    "    # Case 2: Same Level but Different Parent\n",
    "    if curr_level == next_level and curr_parent != next_parent:\n",
    "        df_sub.at[i, \"End Page\"] = next_start_page_org - 1 if next_snp_org else next_start_page_org\n",
    "\n",
    "    # Case 3: Different Level & Different Parent \n",
    "    if curr_level != next_level:\n",
    "        df_sub.at[i, \"End Page\"] = last_page\n",
    "        \n",
    "df_sub.at[len(df_sub) - 1, \"End Page\"] = last_page\n",
    "\n",
    "# Restore original index order before merging\n",
    "df_sub = df_sub.sort_values(by=\"Original Index\").set_index(\"Original Index\")\n",
    "df[\"End Page\"] = df_sub[\"End Page\"]\n",
    "df = df[[\"Parent Section\", \"Section\", \"Section Title\", \"Section Body Text\", \"Start Page\", \"End Page\"]]\n",
    "\n",
    "# Save final DataFrame as CSV\n",
    "df.to_csv(\"final_output_from_json_GPT.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
